### 容器的Cgroups和Namespace技术
**容器的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”**
**Cgroups**用来制造约束的主要手段，**Namespace**修改进程视图的主要方法。
#### Namespace
运行一个docker`docker run -it busybox /bin/sh`，在该容器中运行ps指令   
```shell
/ # ps
PID  USER   TIME COMMAND
  1  root   0:00 /bin/sh
  10 root   0:00 ps

```
从容器中的ps命令可以看出，容器中的`/bin/sh`进程pid=1.  
上面的`ps`和`bin/sh`已经被docker隔离在了一个和宿主机完全不同的世界里。  
**原理**：  
在宿主机上运行`/bin/sh`程序，操作系统会给它分配进程编号，比如pid=100. 而现在，我们通过docker把`/bin/sh`运行在一个容器中，这时候，Docker就会给刚才pid=100的进程施展“障眼法”，让它看不到其他的99个进程，这样改进程就会错误的认为自己是pid=1。  
这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号。可实际上，他们在宿主机的操作系统里，还是原来的第100号进程，**这种技术就是Linux里面的Namespace机制**  
**除了刚才的PID Namespace，Linux还提供了Mount、UTS、IPC、Network和User这些Namespace，用来对各种不同的进程上下文进行“障眼法”操作**  
比如，mount Namespace，用于让被隔离的进程只看到当前Namespace里的挂载信息；network Namespace，用于让被隔离进程看到当前Namespace里的网络设备和配置。  
这就是Linux容器最基本的实现原理。Linux在实际上创建容器进程时，制定了这个进程所需要启用的一组Namespace参数。这样，容器只能“看”到当前的Namespace所限定的资源、文件、设备、状态或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了，**所以说，容器其实就是一种特殊的进程而已**   
**Namespace技术实际上修改了应用进程看到整个计算机“视图”，即它的“视线”被操作系统做了限制，只能“看到”某些执行的内容**  
#### Cgroups
使用虚拟化技术作为应用沙盒，就必须需要hypervisor来负责创建虚拟机，这个虚拟机是真实存在并且需要完成的OS系统才能运行用户的进程，这就不可避免地带来了额外的资源消耗和占用。相比之前，容器化的用户应用，却依然是宿主机上的普通进程，这就意味着以前的虚拟化而带来的性能损耗是不存在的。  
但是基于Namespace的隔离机制相比虚拟化技术也有很多不足：**隔离得不彻底**  ，具体表现一下两点：
1. 既然容器只是运行在宿主机上的一种特殊进程，那么多个容器之间使用的就还是同一个操作系统内核
2. 在Linux内核中，很多资源和对象是不能被Namespace化的
经过Namespace的隔离障眼法后，pid=100的进程与宿主机中其他进程依然是平等的竞争关系，pid=100所使用的资源（比如CPU、内存）可以被其他进程占用，当然该进程也可以把所有的资源吃光。显然这些都不是一个“沙盒”应该表现出来的合理行为。  
而**Linux Cgroups就是Linux内核中用来为进程设置资源限制的一个重要功能。Linux Cgroups的全称是Linux Control Group，它的主要作用，就是限制一个进程组能够使用的资源上线，包括CPU、内存、磁盘、网络带宽等等。**  
cgroups的具体配置文件在`/sys/fs/cgroup`或者`/cgroup`    
```shell
$ ls /sys/fs/cgroup/cpu
cgroup.clone_children cpu.cfs_period_us cpu.rt_period_us  cpu.shares notify_on_release
cgroup.procs      cpu.cfs_quota_us  cpu.rt_runtime_us cpu.stat  tasks
```
可以看到，想限制cpu的话，可以在这个目录中新建目录，然后将进程id等限制条件进行修改，从而到达限制的目的。  
除了CPU子系统外，Cgroups的每一项子系统都有其独有的资源限制能力，比如：
1. blkio，为块设备设定I/O限制，一般用于磁盘等设备
2. cpuset，为进程分配单独的CPU核和对应的内存节点
3. memory，为进程设定内存使用的限制。
**Linux Cgroups**的设计还是比较移动的，简单粗暴的理解，就是一个子系统目录加上一组资源限制文件的组合。对应docker等容器项目，只需要在每个子系统下（CPU等），为每个容器创建一个控制组（目录），然后在启动容器之后，将这个容器的pid等限制条件写入对应文件即可。  
在docker run中可以加入以下参数：  
`$ docker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu /bin/bash`  
在启动容器后，我们可以通过查看Cgroups文件系统下，CPU子系统中，’docker’这个控制组的资源文件来确认：
```shell
$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_period_us 
100000
$ cat /sys/fs/cgroup/cpu/docker/5d5c9f67d/cpu.cfs_quota_us 
20000
```
以上配置文件说明，这个容器CPU带宽只能使用到20%   
**Cgroups的缺点**   
与Namespace的情况类似，Cgroups限制能力也有一些不足地方，被提及最多的是/proc文件系统的问题   
/proc下记录着内核运行状态的一系列特殊文件，可以通过这些文件查看当前系统或者进程的信息，这些文件也是top指令查看信息的主要来源。  
但是在容器中使用top指令，就会发现看到的依然是宿主机的数据。原因是_proc文件系统并不知道用户通过Cgroups给 这个容器做了什么资源限制，即：_proc文件系统并不了解Cgroups限制的存在。在生产环境中，这个问题必须修正，否则容器中应用程序读到的是宿主机上的数据，这会给应用的运行带来极大的困惑和风险，这块可以使用**lxcfs**来解决。